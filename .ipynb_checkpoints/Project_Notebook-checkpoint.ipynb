{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Likes and Dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All important imports go here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we are attempting to view different models' ability to predict likes and dislikes of movies. Below we have downloaded a dataframe from Kaggle that includes different information about movies from 1986-2016. The information includes things such as genre, company, the name of the movie, runtime, etc. What concerns us most is the score column that is included in this dataframe. The movies were each given a score that was ranked out of 10, 10 being the best, 1 being the worst. We want to utilize these scores to be able to build and train a model to predict movies scores accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv', encoding = 'latin-1') #Read in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies.head() #Display dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping unnecessary columns \n",
    "movies = movies.drop(columns =['country', 'rating', 'released', 'votes', 'writer', 'director', 'star'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_score = movies['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Binarizing the movie ratings into zeros and ones for easy classification later on\n",
    "movies['score'][movies['score'] < avg_score]= 0\n",
    "movies['score'][movies['score'] > avg_score]= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Doing a linear regression to find values to replace 0.0 in the budget column \n",
    "x = movies['gross']\n",
    "y = movies['budget']\n",
    "\n",
    "x_constant = sm.add_constant(x)\n",
    "gross_budget_model = sm.OLS(y, x_constant)\n",
    "results = gross_budget_model.fit()\n",
    "print(\"Intercept and slope are:\", results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = results.params[0]\n",
    "b = results.params[1]\n",
    "#Replacing budgets of 0 with the budget values calculated in linear regression model\n",
    "for i in range(movies.shape[0]):\n",
    "    if movies['budget'][i] ==0.0:\n",
    "        gross_val = movies['gross'][i]\n",
    "        y = m*gross_val + b\n",
    "        movies['budget'].iloc[i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing OneHotEncoder for genre labels, this allows genres to be in zeros and ones so we can use them as features\n",
    "#since they are no longer strings\n",
    "encoder = OneHotEncoder()\n",
    "genre = movies['genre']\n",
    "genre_np = genre.to_numpy()\n",
    "genre_ary = encoder.fit_transform(genre_np.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genre_df = pd.DataFrame(genre_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = genre_df.rename({0:'Action', 1:'Adventure', 2:'Animation', 3:'Biography', 4:'Comedy', 5:'Crime', \n",
    "                            6:'Drama', 7:'Family', 8:'Fantasy', 9:'Horror', 10:'Musical', 11:'Mystery', 12:'Romance', \n",
    "                            13:'Sci-Fi', 14:'Thriller', 15:'War', 16:'Western'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies_encoded = pd.concat([movies, genre_df], axis =1)\n",
    "movies_encoded.head() #OneHotEncoder worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_df = movies_encoded.drop(columns=['genre', 'company', 'name'], axis=1)\n",
    "cleaned_df.head() #Cleaned dataframe ready for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cleaned_df.drop(columns=['score'], axis =1)\n",
    "labels = cleaned_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_labels, test_labels = train_test_split(features, labels, train_size =.75,\n",
    "                                                                         test_size = .25, random_state =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a PCA model using kernel rbf along with default C and gamma values. We will also includes 10 components for this PCA which is fewer than the number of features in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating and fiting PCA model, first using 10 components\n",
    "pca = PCA(n_components=10, whiten=True)\n",
    "pca = pca.fit(train_vectors)\n",
    "\n",
    "##Now transforming train and test vectors into PCA train and test vectors\n",
    "pca_train_vectors = pca.transform(train_vectors)\n",
    "pca_test_vectors = pca.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now fitting model using SVC with kernel rbf with default C and gamma values\n",
    "pca_svm = SVC(kernel ='rbf', C=10, gamma = 0.1)\n",
    "pca_model = pca_svm.fit(pca_train_vectors, train_labels)\n",
    "pca_ypred = pca_model.predict(pca_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now printing metrics to look at accuracy of model\n",
    "print('The confusion matrix is \\n', confusion_matrix(test_labels, pca_ypred))\n",
    "print('The classification report is \\n', classification_report(test_labels, pca_ypred))\n",
    "print('The accuracy score is \\n', accuracy_score(test_labels, pca_ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will attempt to make a PCA that has the same number of components as features in our dataset. We will then see if the accuracy scores change at all with this change in number of components. We will keep the kernel as rbf and default C and gamma values, same as the first PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating and fiting PCA model, now using 21 components, which is equal to the number of features in our dataset\n",
    "pca = PCA(n_components=21, whiten=True)\n",
    "pca = pca.fit(train_vectors)\n",
    "\n",
    "##Now transforming train and test vectors into PCA train and test vectors\n",
    "pca_train_vectors = pca.transform(train_vectors)\n",
    "pca_test_vectors = pca.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now fitting model using SVC with kernel rbf with default C and gamma values\n",
    "pca_svm = SVC(kernel ='rbf', C=10, gamma = 0.1)\n",
    "pca_model = pca_svm.fit(pca_train_vectors, train_labels)\n",
    "pca_ypred21 = pca_model.predict(pca_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now printing metrics to look at accuracy of model\n",
    "print('The confusion matrix is \\n', confusion_matrix(test_labels, pca_ypred21))\n",
    "print('The classification report is \\n', classification_report(test_labels, pca_ypred21))\n",
    "print('The accuracy score is \\n', accuracy_score(test_labels, pca_ypred21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score of the PCA with 10 components is \\n', accuracy_score(test_labels, pca_ypred))\n",
    "print('The accuracy score of the PCA with 21 components is \\n', accuracy_score(test_labels, pca_ypred21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the cell above, the accuracy score for both PCAs, one with 10 components and one with 21 components, are pretty much equal. If we look more closely we can see that the accuracy for 21 components is slightly lower than the accuracy for 10 components. This might indicate that we might need to use fewer components and to get a better accuracy since after 10 components the accuracies are the same. Perhaps once we pass 10 components we might be overfitting the data, so it might be a good idea to try a PCA with fewer components, for example 4. The number of features that do not include the OneHotEncoder we did of the genres is four features, so maybe that would be a good number less than 10 that we could try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying a PCA with 4 components to see if we were overfitting with 10 components\n",
    "pca = PCA(n_components=4, whiten=True)\n",
    "pca = pca.fit(train_vectors)\n",
    "\n",
    "##Now transforming train and test vectors into PCA train and test vectors\n",
    "pca_train_vectors = pca.transform(train_vectors)\n",
    "pca_test_vectors = pca.transform(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now fitting model using SVC with kernel rbf with default C and gamma values\n",
    "pca_svm = SVC(kernel ='rbf', C=10, gamma = 0.1)\n",
    "pca_model = pca_svm.fit(pca_train_vectors, train_labels)\n",
    "pca_ypred4 = pca_model.predict(pca_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now printing metrics to look at accuracy of model\n",
    "print('The confusion matrix is \\n', confusion_matrix(test_labels, pca_ypred4))\n",
    "print('The classification report is \\n', classification_report(test_labels, pca_ypred4))\n",
    "print('The accuracy score is \\n', accuracy_score(test_labels, pca_ypred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy score for a PCA with 4 components is \\n', accuracy_score(test_labels, pca_ypred4))\n",
    "print('The accuracy score of the PCA with 10 components is \\n', accuracy_score(test_labels, pca_ypred))\n",
    "print('The accuracy score of the PCA with 21 components is \\n', accuracy_score(test_labels, pca_ypred21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This didn't work either. The accuracy with 4 components seems to be the same as the accuracy with 21 components. However, one interesting thing to look at is the confusion matrix for all three models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('The confusion matrix for a PCA with 4 components is \\n', confusion_matrix(test_labels, pca_ypred4))\n",
    "print('The confusion matrix for a PCA with 21 components is \\n', confusion_matrix(test_labels, pca_ypred21))\n",
    "print('The confusion matrix for a PCA with 10 components is \\n', confusion_matrix(test_labels, pca_ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
