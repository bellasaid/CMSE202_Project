{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Movie Likes and Dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(columns =['country', 'rating', 'released', 'votes', 'writer', 'director', 'star'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_score = movies['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['score'][movies['score'] < avg_score]= 0\n",
    "movies['score'][movies['score'] > avg_score]= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = movies['gross']\n",
    "y = movies['budget']\n",
    "\n",
    "x_constant = sm.add_constant(x)\n",
    "gross_budget_model = sm.OLS(y, x_constant)\n",
    "results = gross_budget_model.fit()\n",
    "print(\"Intercept and slope are:\", results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = results.params[0]\n",
    "b = results.params[1]\n",
    "#budget_df = movies[movies['budget']==0.0]\n",
    "#budget_zero = budget_df['budget']\n",
    "for i in range(movies.shape[0]):\n",
    "    if movies['budget'][i] ==0.0:\n",
    "        gross_val = movies['gross'][i]\n",
    "        y = m*gross_val + b\n",
    "        movies['budget'].iloc[i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "genre = movies['genre']\n",
    "genre_np = genre.to_numpy()\n",
    "genre_ary = encoder.fit_transform(genre_np.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "genre_df = pd.DataFrame(genre_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = genre_df.rename({0:'Action', 1:'Adventure', 2:'Animation', 3:'Biography', 4:'Comedy', 5:'Crime', \n",
    "                            6:'Drama', 7:'Family', 8:'Fantasy', 9:'Horror', 10:'Musical', 11:'Mystery', 12:'Romance', \n",
    "                            13:'Sci-Fi', 14:'Thriller', 15:'War', 16:'Western'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_encoded = pd.concat([movies, genre_df], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = movies_encoded.drop(columns = ['genre', 'company', 'name'])\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = cleaned_df.corr() # making correlation matrix\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (10,8))\n",
    "sea.heatmap(corr, cmap = \"hot\") # passing the correlation matrix into the seaborn heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cleaned_df.drop(columns = ['score']) # capturing feature variables\n",
    "labels = cleaned_df['score'] # capturing like and dislike labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data, using 75% for training the model, random state is set for reproducibility\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, \n",
    "                                                                            train_size = 0.75, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training and testing sets of data, a logistic model is made to try and predict whether a movie was liked or disliked. First, the logistic model is found by passing the classes and features for the training data into the Logit function from the statsmodels package. A constant is added to the training features for this model. Next, the model results of the model can be viewed once it is fitted. Then the test features can be be passed in to get the predictions from the fitted model. Finally, these predictions are matched up with the actual likes and dislikes to evaluate the performance of the model. If the predicted values were above 0.5, then they were classified as liked. Otherwise, they were dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the logistic regression model, adding a constant variable to the features\n",
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_features))\n",
    "\n",
    "# fitting and evaluating the trained model\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "temp = []\n",
    "b = result.predict(sm.add_constant(test_features)) # have to loop through the results and sort the classes\n",
    "for i in b:\n",
    "    if i > 0.5: # if the prediction is higher than 0.5 then it is a like\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "\n",
    "print(\"The accuracy of the model is\", metrics.accuracy_score(y_pred = temp,y_true= test_labels))\n",
    "# accuracy of my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, it is evident that the accuracy of the model was not the best but it is significantly better than if the model was just left to chance. About 66% of movies were correctly guessed to have been liked or disliked. From the summary of the model, it seems that gross, runtime, budget, and year are significant in predicting movie likes. Also, one can see by the p-values that the genre categories and the constant were not very significant in the model. A simplified model can be made to try and increase accuracy without these insignificant features. After reducing the feature set and splitting the data into training and testing sets again, one can follow the previous methods to create the reduced logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping high p value features to make a reduced model\n",
    "features2 = features.drop(columns = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', \n",
    "                            'Drama', 'Family', 'Fantasy', 'Horror', 'Musical', 'Mystery', 'Romance', \n",
    "                            'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
    "\n",
    "\n",
    "# splitting data again, sets of data and classes for training and testing\n",
    "train_features2, test_features2, train_labels2, test_labels2 = train_test_split(features2, labels, \n",
    "                                                                                train_size = 0.75, random_state = 1)\n",
    "\n",
    "\n",
    "logit_model2 = sm.Logit(train_labels2, train_features2) # my logistic model with the new training data, no constant\n",
    "\n",
    "\n",
    "results2 = logit_model2.fit() # fitting the new model\n",
    "\n",
    "temp2 = []\n",
    "b = results2.predict(test_features2) # have to loop through the results and sort the classes\n",
    "for i in b:\n",
    "    if i > 0.5: # same threshold as before\n",
    "        temp2.append(1)\n",
    "    else:\n",
    "        temp2.append(0)\n",
    "\n",
    "        \n",
    "print(results2.summary()) # printing the new results\n",
    "print(\"The accuracy of the new model is\", metrics.accuracy_score(y_pred = temp2,y_true= test_labels2))\n",
    "# accuracy of my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reducing the model, it can be seen that the accuracy dropped a little, although it is nearly the same value as the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
